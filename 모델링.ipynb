{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "모델링.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPUZPeBCHoahduqvgQJcKD0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seokhee516/Project2-Credit-Scoring-System/blob/main/%EB%AA%A8%EB%8D%B8%EB%A7%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byNc0LdXSSG-"
      },
      "source": [
        "# 0. 데이터 및 모듈 불러오기 (추후 합치기)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B51YXCwhS4zM"
      },
      "source": [
        "# !pip install category_encoders"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqg9R0-1SIQ1",
        "outputId": "8c05e982-e1fc-4328-fde7-e4fb95671a5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "HRaCuG-OYOpm",
        "outputId": "d2385afe-4ff6-4107-ff7c-cc3f75bed282"
      },
      "source": [
        "# 데이터 불러오기\n",
        "df = pd.read_csv('Lending_club_data_2018-2020Q3_preprocessed.csv').iloc[:-1,1:]\n",
        "# Default == 1, Paid == 0\n",
        "df.loc[df['loan_payment']=='Default', 'loan_payment'] = 1\n",
        "df.loc[df['loan_payment']=='Paid', 'loan_payment'] = 0\n",
        "\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(110836, 85)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>funded_amnt</th>\n",
              "      <th>funded_amnt_inv</th>\n",
              "      <th>term</th>\n",
              "      <th>int_rate</th>\n",
              "      <th>installment</th>\n",
              "      <th>grade</th>\n",
              "      <th>sub_grade</th>\n",
              "      <th>emp_length</th>\n",
              "      <th>home_ownership</th>\n",
              "      <th>annual_inc</th>\n",
              "      <th>verification_status</th>\n",
              "      <th>issue_d</th>\n",
              "      <th>loan_status</th>\n",
              "      <th>purpose</th>\n",
              "      <th>title</th>\n",
              "      <th>dti</th>\n",
              "      <th>delinq_2yrs</th>\n",
              "      <th>fico_range_low</th>\n",
              "      <th>fico_range_high</th>\n",
              "      <th>inq_last_6mths</th>\n",
              "      <th>open_acc</th>\n",
              "      <th>pub_rec</th>\n",
              "      <th>revol_bal</th>\n",
              "      <th>revol_util</th>\n",
              "      <th>total_acc</th>\n",
              "      <th>initial_list_status</th>\n",
              "      <th>last_fico_range_high</th>\n",
              "      <th>last_fico_range_low</th>\n",
              "      <th>application_type</th>\n",
              "      <th>acc_now_delinq</th>\n",
              "      <th>tot_coll_amt</th>\n",
              "      <th>tot_cur_bal</th>\n",
              "      <th>open_acc_6m</th>\n",
              "      <th>open_act_il</th>\n",
              "      <th>open_il_12m</th>\n",
              "      <th>open_il_24m</th>\n",
              "      <th>mths_since_rcnt_il</th>\n",
              "      <th>total_bal_il</th>\n",
              "      <th>...</th>\n",
              "      <th>total_rev_hi_lim</th>\n",
              "      <th>inq_fi</th>\n",
              "      <th>total_cu_tl</th>\n",
              "      <th>inq_last_12m</th>\n",
              "      <th>acc_open_past_24mths</th>\n",
              "      <th>avg_cur_bal</th>\n",
              "      <th>bc_open_to_buy</th>\n",
              "      <th>bc_util</th>\n",
              "      <th>chargeoff_within_12_mths</th>\n",
              "      <th>delinq_amnt</th>\n",
              "      <th>mo_sin_old_il_acct</th>\n",
              "      <th>mo_sin_old_rev_tl_op</th>\n",
              "      <th>mo_sin_rcnt_rev_tl_op</th>\n",
              "      <th>mo_sin_rcnt_tl</th>\n",
              "      <th>mort_acc</th>\n",
              "      <th>mths_since_recent_bc</th>\n",
              "      <th>mths_since_recent_inq</th>\n",
              "      <th>num_accts_ever_120_pd</th>\n",
              "      <th>num_actv_bc_tl</th>\n",
              "      <th>num_actv_rev_tl</th>\n",
              "      <th>num_bc_sats</th>\n",
              "      <th>num_bc_tl</th>\n",
              "      <th>num_il_tl</th>\n",
              "      <th>num_op_rev_tl</th>\n",
              "      <th>num_rev_accts</th>\n",
              "      <th>num_rev_tl_bal_gt_0</th>\n",
              "      <th>num_sats</th>\n",
              "      <th>num_tl_120dpd_2m</th>\n",
              "      <th>num_tl_30dpd</th>\n",
              "      <th>num_tl_90g_dpd_24m</th>\n",
              "      <th>num_tl_op_past_12m</th>\n",
              "      <th>pct_tl_nvr_dlq</th>\n",
              "      <th>percent_bc_gt_75</th>\n",
              "      <th>pub_rec_bankruptcies</th>\n",
              "      <th>tax_liens</th>\n",
              "      <th>tot_hi_cred_lim</th>\n",
              "      <th>total_bal_ex_mort</th>\n",
              "      <th>total_bc_limit</th>\n",
              "      <th>total_il_high_credit_limit</th>\n",
              "      <th>loan_payment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>133154854.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>60 months</td>\n",
              "      <td>14.03</td>\n",
              "      <td>651.95</td>\n",
              "      <td>C</td>\n",
              "      <td>C2</td>\n",
              "      <td>10+ years</td>\n",
              "      <td>MORTGAGE</td>\n",
              "      <td>125000.0</td>\n",
              "      <td>Verified</td>\n",
              "      <td>May-2018</td>\n",
              "      <td>Charged Off</td>\n",
              "      <td>General loan debt</td>\n",
              "      <td>Home improvement</td>\n",
              "      <td>16.68</td>\n",
              "      <td>0.0</td>\n",
              "      <td>685.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40882.0</td>\n",
              "      <td>75.8</td>\n",
              "      <td>22.0</td>\n",
              "      <td>w</td>\n",
              "      <td>679.0</td>\n",
              "      <td>675.0</td>\n",
              "      <td>Individual</td>\n",
              "      <td>0.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>355111.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>2933.0</td>\n",
              "      <td>...</td>\n",
              "      <td>53900.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27316.0</td>\n",
              "      <td>5197.0</td>\n",
              "      <td>81.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>264.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>95.5</td>\n",
              "      <td>57.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>423905.0</td>\n",
              "      <td>43815.0</td>\n",
              "      <td>28000.0</td>\n",
              "      <td>19068.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>133296608.0</td>\n",
              "      <td>6025.0</td>\n",
              "      <td>6025.0</td>\n",
              "      <td>6025.0</td>\n",
              "      <td>36 months</td>\n",
              "      <td>9.58</td>\n",
              "      <td>193.23</td>\n",
              "      <td>B</td>\n",
              "      <td>B1</td>\n",
              "      <td>10+ years</td>\n",
              "      <td>MORTGAGE</td>\n",
              "      <td>75000.0</td>\n",
              "      <td>Verified</td>\n",
              "      <td>May-2018</td>\n",
              "      <td>Fully Paid</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>Debt consolidation</td>\n",
              "      <td>8.81</td>\n",
              "      <td>0.0</td>\n",
              "      <td>660.0</td>\n",
              "      <td>664.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>w</td>\n",
              "      <td>669.0</td>\n",
              "      <td>665.0</td>\n",
              "      <td>Joint App</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>396237.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>31047.0</td>\n",
              "      <td>...</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>132079.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>106.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>61.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>408401.0</td>\n",
              "      <td>31047.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>38249.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>133465963.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>36 months</td>\n",
              "      <td>11.05</td>\n",
              "      <td>294.87</td>\n",
              "      <td>B</td>\n",
              "      <td>B4</td>\n",
              "      <td>less than 3 years</td>\n",
              "      <td>MORTGAGE</td>\n",
              "      <td>140000.0</td>\n",
              "      <td>Not Verified</td>\n",
              "      <td>May-2018</td>\n",
              "      <td>Current</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>Debt consolidation</td>\n",
              "      <td>10.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>695.0</td>\n",
              "      <td>699.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9024.0</td>\n",
              "      <td>41.8</td>\n",
              "      <td>35.0</td>\n",
              "      <td>w</td>\n",
              "      <td>709.0</td>\n",
              "      <td>705.0</td>\n",
              "      <td>Individual</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54836.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>45812.0</td>\n",
              "      <td>...</td>\n",
              "      <td>21600.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6855.0</td>\n",
              "      <td>2662.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>183.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>97.1</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81369.0</td>\n",
              "      <td>54836.0</td>\n",
              "      <td>9500.0</td>\n",
              "      <td>59769.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>133498757.0</td>\n",
              "      <td>25000.0</td>\n",
              "      <td>25000.0</td>\n",
              "      <td>25000.0</td>\n",
              "      <td>36 months</td>\n",
              "      <td>10.07</td>\n",
              "      <td>807.51</td>\n",
              "      <td>B</td>\n",
              "      <td>B2</td>\n",
              "      <td>10+ years</td>\n",
              "      <td>MORTGAGE</td>\n",
              "      <td>86800.0</td>\n",
              "      <td>Source Verified</td>\n",
              "      <td>May-2018</td>\n",
              "      <td>Current</td>\n",
              "      <td>debt_consolidation</td>\n",
              "      <td>Debt consolidation</td>\n",
              "      <td>18.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>675.0</td>\n",
              "      <td>679.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34132.0</td>\n",
              "      <td>45.8</td>\n",
              "      <td>50.0</td>\n",
              "      <td>w</td>\n",
              "      <td>659.0</td>\n",
              "      <td>655.0</td>\n",
              "      <td>Individual</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>218306.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>74600.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>8732.0</td>\n",
              "      <td>12603.0</td>\n",
              "      <td>67.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>266.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>81.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>264608.0</td>\n",
              "      <td>34132.0</td>\n",
              "      <td>38700.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>133843310.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>60 months</td>\n",
              "      <td>14.52</td>\n",
              "      <td>235.39</td>\n",
              "      <td>C</td>\n",
              "      <td>C3</td>\n",
              "      <td>10+ years</td>\n",
              "      <td>RENT</td>\n",
              "      <td>36000.0</td>\n",
              "      <td>Not Verified</td>\n",
              "      <td>May-2018</td>\n",
              "      <td>Fully Paid</td>\n",
              "      <td>General loan debt</td>\n",
              "      <td>Home improvement</td>\n",
              "      <td>20.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>770.0</td>\n",
              "      <td>774.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4867.0</td>\n",
              "      <td>17.7</td>\n",
              "      <td>17.0</td>\n",
              "      <td>w</td>\n",
              "      <td>744.0</td>\n",
              "      <td>740.0</td>\n",
              "      <td>Joint App</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18659.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>13792.0</td>\n",
              "      <td>...</td>\n",
              "      <td>27500.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1555.0</td>\n",
              "      <td>11854.0</td>\n",
              "      <td>26.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>167.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>28.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>51989.0</td>\n",
              "      <td>18659.0</td>\n",
              "      <td>16100.0</td>\n",
              "      <td>24489.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 85 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  loan_amnt  ...  total_il_high_credit_limit  loan_payment\n",
              "0  133154854.0    28000.0  ...                     19068.0             1\n",
              "1  133296608.0     6025.0  ...                     38249.0             0\n",
              "2  133465963.0     9000.0  ...                     59769.0             0\n",
              "3  133498757.0    25000.0  ...                         0.0             0\n",
              "4  133843310.0    10000.0  ...                     24489.0             0\n",
              "\n",
              "[5 rows x 85 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCj9tlRNQ0JT"
      },
      "source": [
        "# 빈도가 100%인 변수 제거\n",
        "df.drop(columns=['num_tl_120dpd_2m', 'acc_now_delinq', 'num_tl_30dpd'],axis=1, inplace=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpzmDsQWS82h"
      },
      "source": [
        "# 3. 모델링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qLjUGkMV682"
      },
      "source": [
        "# 평가지표 함수\n",
        "def model_evaluation(label, predict):\n",
        "    cf_matrix = confusion_matrix(label, predict)\n",
        "    Accuracy = (cf_matrix[0][0] + cf_matrix[1][1]) / sum(sum(cf_matrix))\n",
        "    Precision = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[0][1])\n",
        "    Recall = cf_matrix[1][1] / (cf_matrix[1][1] + cf_matrix[1][0])\n",
        "    F1_Score = (2 * Recall * Precision) / (Recall + Precision)\n",
        "    print(\"Model_Evaluation with Label: Default\")\n",
        "    print(\"Accuracy: \", Accuracy)\n",
        "    print(\"Precision: \", Precision)\n",
        "    print(\"Recall: \", Recall)\n",
        "    print(\"F1-Score: \", F1_Score)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRlOmhYfTDtL"
      },
      "source": [
        "## 3.1 타겟 지정 및 데이터 세트 분할"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48Dcu0R9WSA6",
        "outputId": "4d29ffd9-ffca-4393-dd60-4c3c74b1d1f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "df[df['issue_d'] == 'Sep-2020']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>funded_amnt</th>\n",
              "      <th>funded_amnt_inv</th>\n",
              "      <th>term</th>\n",
              "      <th>int_rate</th>\n",
              "      <th>installment</th>\n",
              "      <th>grade</th>\n",
              "      <th>sub_grade</th>\n",
              "      <th>emp_length</th>\n",
              "      <th>home_ownership</th>\n",
              "      <th>annual_inc</th>\n",
              "      <th>verification_status</th>\n",
              "      <th>issue_d</th>\n",
              "      <th>loan_status</th>\n",
              "      <th>purpose</th>\n",
              "      <th>title</th>\n",
              "      <th>dti</th>\n",
              "      <th>delinq_2yrs</th>\n",
              "      <th>fico_range_low</th>\n",
              "      <th>fico_range_high</th>\n",
              "      <th>inq_last_6mths</th>\n",
              "      <th>open_acc</th>\n",
              "      <th>pub_rec</th>\n",
              "      <th>revol_bal</th>\n",
              "      <th>revol_util</th>\n",
              "      <th>total_acc</th>\n",
              "      <th>initial_list_status</th>\n",
              "      <th>last_fico_range_high</th>\n",
              "      <th>last_fico_range_low</th>\n",
              "      <th>application_type</th>\n",
              "      <th>tot_coll_amt</th>\n",
              "      <th>tot_cur_bal</th>\n",
              "      <th>open_acc_6m</th>\n",
              "      <th>open_act_il</th>\n",
              "      <th>open_il_12m</th>\n",
              "      <th>open_il_24m</th>\n",
              "      <th>mths_since_rcnt_il</th>\n",
              "      <th>total_bal_il</th>\n",
              "      <th>il_util</th>\n",
              "      <th>...</th>\n",
              "      <th>max_bal_bc</th>\n",
              "      <th>all_util</th>\n",
              "      <th>total_rev_hi_lim</th>\n",
              "      <th>inq_fi</th>\n",
              "      <th>total_cu_tl</th>\n",
              "      <th>inq_last_12m</th>\n",
              "      <th>acc_open_past_24mths</th>\n",
              "      <th>avg_cur_bal</th>\n",
              "      <th>bc_open_to_buy</th>\n",
              "      <th>bc_util</th>\n",
              "      <th>chargeoff_within_12_mths</th>\n",
              "      <th>delinq_amnt</th>\n",
              "      <th>mo_sin_old_il_acct</th>\n",
              "      <th>mo_sin_old_rev_tl_op</th>\n",
              "      <th>mo_sin_rcnt_rev_tl_op</th>\n",
              "      <th>mo_sin_rcnt_tl</th>\n",
              "      <th>mort_acc</th>\n",
              "      <th>mths_since_recent_bc</th>\n",
              "      <th>mths_since_recent_inq</th>\n",
              "      <th>num_accts_ever_120_pd</th>\n",
              "      <th>num_actv_bc_tl</th>\n",
              "      <th>num_actv_rev_tl</th>\n",
              "      <th>num_bc_sats</th>\n",
              "      <th>num_bc_tl</th>\n",
              "      <th>num_il_tl</th>\n",
              "      <th>num_op_rev_tl</th>\n",
              "      <th>num_rev_accts</th>\n",
              "      <th>num_rev_tl_bal_gt_0</th>\n",
              "      <th>num_sats</th>\n",
              "      <th>num_tl_90g_dpd_24m</th>\n",
              "      <th>num_tl_op_past_12m</th>\n",
              "      <th>pct_tl_nvr_dlq</th>\n",
              "      <th>percent_bc_gt_75</th>\n",
              "      <th>pub_rec_bankruptcies</th>\n",
              "      <th>tax_liens</th>\n",
              "      <th>tot_hi_cred_lim</th>\n",
              "      <th>total_bal_ex_mort</th>\n",
              "      <th>total_bc_limit</th>\n",
              "      <th>total_il_high_credit_limit</th>\n",
              "      <th>loan_payment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows × 82 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [id, loan_amnt, funded_amnt, funded_amnt_inv, term, int_rate, installment, grade, sub_grade, emp_length, home_ownership, annual_inc, verification_status, issue_d, loan_status, purpose, title, dti, delinq_2yrs, fico_range_low, fico_range_high, inq_last_6mths, open_acc, pub_rec, revol_bal, revol_util, total_acc, initial_list_status, last_fico_range_high, last_fico_range_low, application_type, tot_coll_amt, tot_cur_bal, open_acc_6m, open_act_il, open_il_12m, open_il_24m, mths_since_rcnt_il, total_bal_il, il_util, open_rv_12m, open_rv_24m, max_bal_bc, all_util, total_rev_hi_lim, inq_fi, total_cu_tl, inq_last_12m, acc_open_past_24mths, avg_cur_bal, bc_open_to_buy, bc_util, chargeoff_within_12_mths, delinq_amnt, mo_sin_old_il_acct, mo_sin_old_rev_tl_op, mo_sin_rcnt_rev_tl_op, mo_sin_rcnt_tl, mort_acc, mths_since_recent_bc, mths_since_recent_inq, num_accts_ever_120_pd, num_actv_bc_tl, num_actv_rev_tl, num_bc_sats, num_bc_tl, num_il_tl, num_op_rev_tl, num_rev_accts, num_rev_tl_bal_gt_0, num_sats, num_tl_90g_dpd_24m, num_tl_op_past_12m, pct_tl_nvr_dlq, percent_bc_gt_75, pub_rec_bankruptcies, tax_liens, tot_hi_cred_lim, total_bal_ex_mort, total_bc_limit, total_il_high_credit_limit, loan_payment]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 82 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08SeADYPZrIk"
      },
      "source": [
        "target= 'loan_payment'\n",
        "\n",
        "# test set 만들기\n",
        "test = df[(df['issue_d'] == 'Sep-2020') | (df['issue_d'] == 'May-2020')]\n",
        "train = df.drop(test.index)\n",
        "\n",
        "# validation set 만들기\n",
        "train, val = train_test_split(train, train_size = 0.8, stratify=train[target], random_state=10)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBPnopbbehhZ"
      },
      "source": [
        "# target 지정 및 데이터 세트 분할\n",
        "# loan_payment: Target, id: Always unique, issue_d: Date, grade: Duplicative of sub_grade\n",
        "features = train.drop(columns=['loan_status','loan_payment','id','issue_d','grade']).columns\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "X_test = test[features]\n",
        "y_test = test[target]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV3ivyBvizVJ",
        "outputId": "5967964d-f1b2-4d9f-986a-cbddbe8a3fe8"
      },
      "source": [
        "print('X_train shape', X_train.shape)\n",
        "print('X_val shape', X_val.shape)\n",
        "print('X_test shape', X_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape (88668, 77)\n",
            "X_val shape (22168, 77)\n",
            "X_test shape (0, 77)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyi3j7huS8V_"
      },
      "source": [
        "# Data Processing Pipeline\n",
        "processor = make_pipeline(\n",
        "    OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='mean')\n",
        ")\n",
        "X_train_processed = processor.fit_transform(X_train)\n",
        "X_val_processed = processor.transform(X_val)\n",
        "\n",
        "# Scailing\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_processed)\n",
        "X_val_scaled = scaler.transform(X_val_processed)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVjjxMZEkJg_"
      },
      "source": [
        "## 3.2 기본값 모델링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwRqaibljmA9",
        "outputId": "f4cacd4c-9e73-4043-97ff-e14ffa6da9b6"
      },
      "source": [
        "y_train.value_counts(normalize=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.886724\n",
              "1    0.113276\n",
              "Name: loan_payment, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "WgR1AjhqkVpY",
        "outputId": "b6e155ce-3642-4403-c06a-da3059e81cd5"
      },
      "source": [
        "sns.countplot(x=y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fea9440e950>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "0RSJb4UekhGk",
        "outputId": "8a218b03-0923-4e99-86f4-583a3ab5c85a"
      },
      "source": [
        "# Majority class baseline\n",
        "# 기준모델 학습세트\n",
        "major = y_train.mode()[0]\n",
        "y_pred = [major] *len(y_train)\n",
        "print(\"기준모델 학습세트 평가\")\n",
        "model_evaluation(y_train, y_pred)\n",
        "print(\"\\n\")\n",
        "\n",
        "# 기준모델 검증세트\n",
        "y_val = val[target]\n",
        "y_pred = [major] * len(y_val)\n",
        "print(\"기준모델 검증세트 평가\")\n",
        "model_evaluation(y_val, y_pred)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "기준모델 학습세트 평가\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b772b30c7590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"기준모델 학습세트 평가\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-6c450ceecb40>\u001b[0m in \u001b[0;36mmodel_evaluation\u001b[0;34m(label, predict)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 평가지표 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcf_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcf_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mPrecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcf_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcf_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcf_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of unknown and binary targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vC7Smk1V64L",
        "outputId": "e56889c7-79c8-4dea-d9e0-215289c1485d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "elkU03Nam3MP",
        "outputId": "3b93aaea-5a31-4325-c092-d909fabe118a"
      },
      "source": [
        "# Logistic Regression\n",
        "lr = LogisticRegression(random_state=10, n_jobs=-1)\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = lr.predict(X_val_scaled)\n",
        "\n",
        "print(\"로지스틱 검증세트 평가\")\n",
        "model_evaluation(y_val, y_pred_lr)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-641b6b781b30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Logistic Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_pred_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m   1527\u001b[0m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0;32m-> 1528\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'unknown'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QJoEilFJnLP"
      },
      "source": [
        "# Decision Tree Classifier\n",
        "dtc = DecisionTreeClassifier(random_state=1)\n",
        "dtc.fit(X_train_processed, y_train)\n",
        "y_pred_dtc = dtc.predict(X_val_processed)\n",
        "\n",
        "print(\"결정트리 검증세트 평가\")\n",
        "model_evaluation(y_val, y_pred_dtc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_wotVEsXxpb"
      },
      "source": [
        "## 3.4 SMOTE를 이용한 Oversampling 후 모델링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYNayILHYovB"
      },
      "source": [
        "print(\"OverSampling 전, 'Default' 라벨의 수: {}\".format(sum(y_train == 'Default')))\n",
        "print(\"OverSampling 전, 'Paid' 라벨의 수: {}\".format(sum(y_train == 'Paid')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkfwakMaAGO"
      },
      "source": [
        "# SMOTE 알고리즘 활용하여 Oversampling 진행\n",
        "sm = SMOTE(random_state = 10, ratio = 0.3) \n",
        "X_train_res, y_train_res = sm.fit_sample(X_train_processed, y_train.ravel()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmWX2MBVaLkd"
      },
      "source": [
        "print(\"OverSampling 후, 'Default' 라벨의 수: {}\".format(sum(y_train_res == 'Default')))\n",
        "print(\"OverSampling 후, 'Paid' 라벨의 수: {}\".format(sum(y_train_res == 'Paid')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yWbjZdOahm7"
      },
      "source": [
        "pd.Series(y_train_res).value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk5EXx_teUWK"
      },
      "source": [
        "sns.countplot(x=pd.Series(y_train_res))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYPVMjLLfH3q"
      },
      "source": [
        "# Logistic Regression Over Sampling\n",
        "lr2 = LogisticRegression(random_state=10, n_jobs=-1)\n",
        "lr2.fit(X_train_res, y_train_res)\n",
        "y_pred_lr2 = lr2.predict(X_val_scaled)\n",
        "\n",
        "print(\"로지스틱 검증세트 평가\")\n",
        "model_evaluation(y_val, y_pred_lr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfuh4qLkJIKh"
      },
      "source": [
        "# Decision Tree Classifier Over Sampling\n",
        "dtc2 = DecisionTreeClassifier(random_state=10)\n",
        "dtc2.fit(X_train_res, y_train_res)\n",
        "y_pred_dtc2 = dtc2.predict(X_val_processed)\n",
        "\n",
        "print(\"결정트리 검증세트 평가\")\n",
        "model_evaluation(y_val, y_pred_dtc2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIVZTmLTKUYX"
      },
      "source": [
        "# Random Forest Classifier Over Sampling\n",
        "rfc2 = RandomForestClassifier(random_state=1, n_jobs=-1)\n",
        "rfc2.fit(X_train_res, y_train_res)\n",
        "y_pred_rfc2 = rfc2.predict(X_val_processed)\n",
        "\n",
        "print(\"렌덤포레스트 검증세트 평가\")\n",
        "model_evaluation(y_val, y_pred_rfc2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynq4gKTkbtVL"
      },
      "source": [
        "# 3.5 Hyperparameter Tuning 후 모델링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpMPlsqLd6ZI"
      },
      "source": [
        "vc = y_train.value_counts().to_list()\n",
        "ratio = float(vc[0]/vc[1])\n",
        "ratio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3Z3e9fhbSJ9"
      },
      "source": [
        "# XGBClassifier Hyperparameter Tuning\n",
        "xgb3 = XGBClassifier(random_state=10, n_jobs=-1,n_estimators=1000, max_depth=7, \n",
        "                     scale_pos_weight=ratio) # weight 조절\n",
        "\n",
        "eval_set = [(X_train_processed, y_train), \n",
        "            (X_val_processed, y_val)]\n",
        "\n",
        "xgb3.fit(X_train_processed, y_train,\n",
        "         eval_set=eval_set, eval_metric='error', early_stopping_rounds=50)\n",
        "y_pred_xgb3 = xgb3.predict(X_val_processed)\n",
        "\n",
        "\n",
        "print(\"XGBoost 검증세트 평가\")\n",
        "model_evaluation(y_val, y_pred_xgb3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp2ZxVKBaRbH"
      },
      "source": [
        "# 3.6 Over Sampling + Hyperparameter Tuning 후 모델링"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aO5kM44b1Z3n"
      },
      "source": [
        "# RandomForestClassifier Over Sampling + Hyperparameter Tuning\n",
        "rfc2 = RandomForestClassifier(random_state=10, n_jobs=-1, max_depth=4, n_estimators=300)\n",
        "rfc2.fit(X_train_res, y_train_res)\n",
        "y_pred_rfc2 = rfc2.predict(X_val_processed)\n",
        "\n",
        "print(\"랜덤포레스트 검증세트 평가\")\n",
        "model_evaluation(y_val, y_pred_rfc2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAUDw9GX9GKb"
      },
      "source": [
        "## 4. 데이터 다시 전처리\n",
        "- feature importance 확인\n",
        "- correlation 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCKXyQ5l9alE"
      },
      "source": [
        "feature_names = X_train.columns.tolist()\n",
        "pd.Series(xgb3.feature_importances_, feature_names).sort_values(ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxX9I_Jl_4aQ"
      },
      "source": [
        "sns.distplot(df['last_fico_range_high'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFuQ8Sev9x9z"
      },
      "source": [
        "df[['loan_payment','last_fico_range_high','funded_amnt_inv']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcMlnH45BY_k"
      },
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "sns.heatmap(df.drop(columns=['loan_status','id','issue_d','grade']).corr())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}